{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deap\n",
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWwcZ3zgDAmR",
        "outputId": "ac0f0e5c-507e-4b2d-ee3c-1bce63254c38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.26.4)\n",
            "Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.1\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT0FvAHXC1rf",
        "outputId": "756e6f2e-197c-410f-e53e-8cf93d04e7e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Fumador', 'DedosAmarillos', 'Ansiedad', 'Hipertension',\n",
              "       'EnfermedadCronica', 'Fatiga', 'Alergia', 'Silbidos',\n",
              "       'ConsumidorAlcohol', 'Tos', 'DificultadRespirar', 'DificultadTragar',\n",
              "       'DolorPecho', 'Sexo_F', 'Sexo_M', 'RangoEdad_20-59', 'RangoEdad_59-67',\n",
              "       'RangoEdad_67-87', 'CancerPulmon'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import random\n",
        "import operator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from deap import base, creator, tools, gp\n",
        "import multiprocessing\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('/content/lungcancer_binario.csv')\n",
        "\n",
        "def convert_to_binary(df):\n",
        "    df_binary = df.copy()\n",
        "\n",
        "    for column in df_binary.columns:\n",
        "        # Verifica si la columna es binaria (0/1)\n",
        "        if df_binary[column].dtype in ['int64', 'float64']:\n",
        "            if df_binary[column].nunique() == 2:\n",
        "                df_binary[column].astype(int)  # No modificar columnas binarias\n",
        "            elif df_binary[column].nunique() > 3:\n",
        "                # Aplica binning y luego one-hot\n",
        "                df_binned = pd.cut(df_binary[column], bins=3, labels=False)\n",
        "                df_one_hot = pd.get_dummies(df_binned, prefix=column)\n",
        "                df_binary = pd.concat([df_binary, df_one_hot], axis=1).astype(int)\n",
        "                df_binary.drop(column, axis=1, inplace=True)\n",
        "            else:\n",
        "                # Aplica one-hot directamente\n",
        "                df_one_hot = pd.get_dummies(df_binary[column], prefix=column)\n",
        "                df_binary = pd.concat([df_binary, df_one_hot], axis=1).astype(int)\n",
        "                df_binary.drop(column, axis=1, inplace=True)\n",
        "        elif df_binary[column].dtype == 'object':\n",
        "            # Si la columna es categórica, aplica one-hot\n",
        "            df_one_hot = pd.get_dummies(df_binary[column], prefix=column)\n",
        "            df_binary = pd.concat([df_binary, df_one_hot], axis=1)\n",
        "            df_binary.drop(column, axis=1, inplace=True)\n",
        "\n",
        "    return df_binary\n",
        "# Convert categorical variables to binary (one-hot encoding)\n",
        "df_bin = convert_to_binary(df)\n",
        "df_bin.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df_bin.drop(['CancerPulmon'], axis=1)\n",
        "Y = df_bin['CancerPulmon']\n",
        "\n",
        "# Convert DataFrames to NumPy arrays for faster computations\n",
        "X = X.values.astype(int)\n",
        "Y = Y.values.astype(int)\n",
        "\n",
        "# Split into train and test sets\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
        "\n",
        "# Define logical functions\n",
        "def logical_and(a, b):\n",
        "    return int(a and b)\n",
        "\n",
        "def logical_or(a, b):\n",
        "    return int(a or b)\n",
        "\n",
        "def logical_not(a):\n",
        "    return int(not a)\n",
        "\n",
        "# Number of variables (features)\n",
        "# Con esto creamos x1, x2, x3... almacenados en una lista\n",
        "num_vars = Xtrain.shape[1]\n",
        "var_names = ['x' + str(i+1) for i in range(num_vars)]\n",
        "\n",
        "# Create PrimitiveSet\n",
        "# Se crea el conjunto de primitivas \"MAIN\" (el conjunto de funciones y operadores que\n",
        "# sirven para construir inidividuos) con el tamaño del número de características\n",
        "# que tenemos en el problema\n",
        "pset = gp.PrimitiveSet(\"MAIN\", num_vars)\n",
        "# Se renombran los argumentos (por defecto llamados ARG0,ARG1...) para que se llamen (x1,x2...)\n",
        "pset.renameArguments(**{'ARG' + str(i): var_names[i] for i in range(num_vars)})\n",
        "\n",
        "# Add primitives to the set\n",
        "# Añade las funciones al conjunto de primitivas\n",
        "pset.addPrimitive(logical_and, 2)\n",
        "pset.addPrimitive(logical_or, 2)\n",
        "pset.addPrimitive(logical_not, 1)\n",
        "\n",
        "# Terminal set can include constants if needed (e.g., True/False)\n",
        "# pset.addTerminal(1)  # Optional: Add constant 'True'\n",
        "# pset.addTerminal(0)  # Optional: Add constant 'False'\n",
        "\n",
        "# Define fitness and individual classes\n",
        "# Se crea una clase FitnessMax que maximiza el fitness de los individuos\n",
        "# Se define una clase \"Individual\" que representa a los individuos de la población\n",
        "# (Se obliga a que sean árboles formados por las primitivas de antes)\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
        "\n",
        "# Create toolbox\n",
        "# Se crea una toolbox que contiene las funciones (herramientas) que se van a usar\n",
        "# para generar individuos poblaciones...\n",
        "toolbox = base.Toolbox()\n",
        "# Función para generar expresiones (gp.genHalfAndHalf sirve para crear árboles\n",
        "# utilizando crecimiento completo=hasta la máxima longitud y crecimiento\n",
        "#parcial=árboles de tamaño libre)\n",
        "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n",
        "# Función para crear individuos (usando la anterior función)\n",
        "toolbox.register(\"individual\", tools.initIterate,\n",
        "                 creator.Individual, toolbox.expr)\n",
        "# Función para crear población, llamando repetidamente a la función anterior\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Register compile function\n",
        "# Función para convertir un individuo (su árbol) en una función de Python ejecutable\n",
        "# esto sirve para poder evaluar a los individuos\n",
        "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
        "\n",
        "# Evaluation function\n",
        "# Para medir el f1-score\n",
        "def eval_individual(individual):\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    predictions = []\n",
        "    for i in range(len(Xtrain)):\n",
        "        args = tuple(Xtrain[i])\n",
        "        pred = func(*args)\n",
        "        predictions.append(pred)\n",
        "    y_pred = np.array(predictions)\n",
        "    y_true = Ytrain\n",
        "    # Compute F1 score\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / \\\n",
        "        (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f1,\n",
        "\n",
        "# Register evaluation function\n",
        "# Para añadir la función anterior al conjunto de herramientas\n",
        "toolbox.register(\"evaluate\", eval_individual)\n",
        "\n",
        "# Genetic operators\n",
        "# Funciones de selección por torneos, cruce (en un punto), generación de árboles\n",
        "#completos y mutación uniforme del árbol generado\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"mate\", gp.cxOnePoint)\n",
        "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
        "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
        "\n",
        "# Limit the height of the tree to prevent bloat\n",
        "# Estas funciones limitan, tanto el cruce como la mutación para que los árboles\n",
        "# resultantes no superen la altura definida\n",
        "# Se podrían eliminar para no limitar el crecimiento de los árboles\n",
        "MAX_HEIGHT = 5\n",
        "MAX_SIZE = 50  # Ajusta este valor según tus necesidades\n",
        "toolbox.decorate(\"mate\", gp.staticLimit(\n",
        "    key=operator.attrgetter(\"height\"), max_value=MAX_HEIGHT))\n",
        "toolbox.decorate(\"mate\", gp.staticLimit(key=len, max_value=MAX_SIZE))\n",
        "toolbox.decorate(\"mutate\", gp.staticLimit(\n",
        "    key=operator.attrgetter(\"height\"), max_value=MAX_HEIGHT))\n",
        "toolbox.decorate(\"mutate\", gp.staticLimit(key=len, max_value=MAX_SIZE))\n",
        "def main():\n",
        "    random.seed(42)\n",
        "    pop = toolbox.population(n=300)\n",
        "    hof = tools.HallOfFame(1)\n",
        "\n",
        "    # Statistics\n",
        "    # Métricas sobre el tamaño del inviduo y de su fitness\n",
        "    stats_fit = tools.Statistics(lambda ind: ind.fitness.values[0])\n",
        "    stats_size = tools.Statistics(len)\n",
        "    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
        "    mstats.register(\"avg\", np.mean)\n",
        "    mstats.register(\"std\", np.std)\n",
        "    mstats.register(\"min\", np.min)\n",
        "    mstats.register(\"max\", np.max)\n",
        "\n",
        "    # Use multiprocessing for parallel evaluations\n",
        "    # Para optimizar el proceso evolutivo\n",
        "    pool = multiprocessing.Pool()\n",
        "    toolbox.register(\"map\", pool.map)\n",
        "\n",
        "    # Evaluate the entire population\n",
        "    # Evalúa en paralelo los individuos\n",
        "    fitnesses = list(toolbox.map(toolbox.evaluate, pop))\n",
        "    for ind, fit in zip(pop, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    # Update the hall of fame with the initial population\n",
        "    hof.update(pop)\n",
        "\n",
        "    ngen = 150\n",
        "    for gen in range(ngen):\n",
        "        # Select the next generation individuals\n",
        "        offspring = toolbox.select(pop, len(pop) - 1)\n",
        "        # Clone the selected individuals\n",
        "        offspring = list(map(toolbox.clone, offspring))\n",
        "        # Apply crossover and mutation\n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "            if random.random() < 0.5:  # Curce con prob = 50%\n",
        "                toolbox.mate(child1, child2)\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "        for mutant in offspring:\n",
        "            if random.random() < 0.2: # Mutación con prob = 20%\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "        # Evaluate the individuals with invalid fitness\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "        # Replace the population with the offspring, keeping the best individual\n",
        "        pop[:] = offspring + [hof[0]]\n",
        "        # Update the hall of fame\n",
        "        hof.update(pop)\n",
        "        # Record statistics\n",
        "        record = mstats.compile(pop)\n",
        "        print(f\"Gen {gen}: Max F1 Score = {record['fitness']['max']:.4f}\")\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return pop, hof\n",
        "\n",
        "def evaluate_on_test_set(individual):\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    predictions = []\n",
        "    for i in range(len(Xtest)):\n",
        "        args = tuple(Xtest[i])\n",
        "        pred = func(*args)\n",
        "        predictions.append(pred)\n",
        "    y_pred = np.array(predictions)\n",
        "    y_true = Ytest\n",
        "    # Compute F1 score\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / \\\n",
        "        (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pop, hof = main()\n",
        "    best_individual = hof[0]\n",
        "    print(\"\\nBest individual:\")\n",
        "    print(best_individual)\n",
        "    print(\"\\nBest training F1 Score:\", best_individual.fitness.values[0])\n",
        "    test_f1 = evaluate_on_test_set(best_individual)\n",
        "    print(\"Test F1 Score:\", test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxsXW-qUVAXQ",
        "outputId": "f5e6d580-a4ab-4ef1-c2c6-1a3608919bd7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen 0: Max F1 Score = 0.9429\n",
            "Gen 1: Max F1 Score = 0.9487\n",
            "Gen 2: Max F1 Score = 0.9487\n",
            "Gen 3: Max F1 Score = 0.9487\n",
            "Gen 4: Max F1 Score = 0.9502\n",
            "Gen 5: Max F1 Score = 0.9533\n",
            "Gen 6: Max F1 Score = 0.9554\n",
            "Gen 7: Max F1 Score = 0.9554\n",
            "Gen 8: Max F1 Score = 0.9554\n",
            "Gen 9: Max F1 Score = 0.9554\n",
            "Gen 10: Max F1 Score = 0.9554\n",
            "Gen 11: Max F1 Score = 0.9557\n",
            "Gen 12: Max F1 Score = 0.9557\n",
            "Gen 13: Max F1 Score = 0.9557\n",
            "Gen 14: Max F1 Score = 0.9557\n",
            "Gen 15: Max F1 Score = 0.9557\n",
            "Gen 16: Max F1 Score = 0.9557\n",
            "Gen 17: Max F1 Score = 0.9576\n",
            "Gen 18: Max F1 Score = 0.9578\n",
            "Gen 19: Max F1 Score = 0.9578\n",
            "Gen 20: Max F1 Score = 0.9580\n",
            "Gen 21: Max F1 Score = 0.9602\n",
            "Gen 22: Max F1 Score = 0.9604\n",
            "Gen 23: Max F1 Score = 0.9604\n",
            "Gen 24: Max F1 Score = 0.9604\n",
            "Gen 25: Max F1 Score = 0.9604\n",
            "Gen 26: Max F1 Score = 0.9628\n",
            "Gen 27: Max F1 Score = 0.9628\n",
            "Gen 28: Max F1 Score = 0.9628\n",
            "Gen 29: Max F1 Score = 0.9628\n",
            "Gen 30: Max F1 Score = 0.9628\n",
            "Gen 31: Max F1 Score = 0.9628\n",
            "Gen 32: Max F1 Score = 0.9630\n",
            "Gen 33: Max F1 Score = 0.9630\n",
            "Gen 34: Max F1 Score = 0.9630\n",
            "Gen 35: Max F1 Score = 0.9630\n",
            "Gen 36: Max F1 Score = 0.9630\n",
            "Gen 37: Max F1 Score = 0.9630\n",
            "Gen 38: Max F1 Score = 0.9630\n",
            "Gen 39: Max F1 Score = 0.9630\n",
            "Gen 40: Max F1 Score = 0.9630\n",
            "Gen 41: Max F1 Score = 0.9630\n",
            "Gen 42: Max F1 Score = 0.9630\n",
            "Gen 43: Max F1 Score = 0.9653\n",
            "Gen 44: Max F1 Score = 0.9653\n",
            "Gen 45: Max F1 Score = 0.9653\n",
            "Gen 46: Max F1 Score = 0.9653\n",
            "Gen 47: Max F1 Score = 0.9653\n",
            "Gen 48: Max F1 Score = 0.9653\n",
            "Gen 49: Max F1 Score = 0.9653\n",
            "Gen 50: Max F1 Score = 0.9653\n",
            "Gen 51: Max F1 Score = 0.9653\n",
            "Gen 52: Max F1 Score = 0.9653\n",
            "Gen 53: Max F1 Score = 0.9653\n",
            "Gen 54: Max F1 Score = 0.9653\n",
            "Gen 55: Max F1 Score = 0.9653\n",
            "Gen 56: Max F1 Score = 0.9653\n",
            "Gen 57: Max F1 Score = 0.9653\n",
            "Gen 58: Max F1 Score = 0.9653\n",
            "Gen 59: Max F1 Score = 0.9653\n",
            "Gen 60: Max F1 Score = 0.9653\n",
            "Gen 61: Max F1 Score = 0.9653\n",
            "Gen 62: Max F1 Score = 0.9653\n",
            "Gen 63: Max F1 Score = 0.9653\n",
            "Gen 64: Max F1 Score = 0.9653\n",
            "Gen 65: Max F1 Score = 0.9653\n",
            "Gen 66: Max F1 Score = 0.9653\n",
            "Gen 67: Max F1 Score = 0.9653\n",
            "Gen 68: Max F1 Score = 0.9653\n",
            "Gen 69: Max F1 Score = 0.9653\n",
            "Gen 70: Max F1 Score = 0.9653\n",
            "Gen 71: Max F1 Score = 0.9653\n",
            "Gen 72: Max F1 Score = 0.9653\n",
            "Gen 73: Max F1 Score = 0.9653\n",
            "Gen 74: Max F1 Score = 0.9653\n",
            "Gen 75: Max F1 Score = 0.9653\n",
            "Gen 76: Max F1 Score = 0.9653\n",
            "Gen 77: Max F1 Score = 0.9653\n",
            "Gen 78: Max F1 Score = 0.9653\n",
            "Gen 79: Max F1 Score = 0.9653\n",
            "Gen 80: Max F1 Score = 0.9653\n",
            "Gen 81: Max F1 Score = 0.9653\n",
            "Gen 82: Max F1 Score = 0.9653\n",
            "Gen 83: Max F1 Score = 0.9653\n",
            "Gen 84: Max F1 Score = 0.9653\n",
            "Gen 85: Max F1 Score = 0.9653\n",
            "Gen 86: Max F1 Score = 0.9653\n",
            "Gen 87: Max F1 Score = 0.9653\n",
            "Gen 88: Max F1 Score = 0.9653\n",
            "Gen 89: Max F1 Score = 0.9653\n",
            "Gen 90: Max F1 Score = 0.9653\n",
            "Gen 91: Max F1 Score = 0.9653\n",
            "Gen 92: Max F1 Score = 0.9653\n",
            "Gen 93: Max F1 Score = 0.9653\n",
            "Gen 94: Max F1 Score = 0.9653\n",
            "Gen 95: Max F1 Score = 0.9653\n",
            "Gen 96: Max F1 Score = 0.9653\n",
            "Gen 97: Max F1 Score = 0.9653\n",
            "Gen 98: Max F1 Score = 0.9653\n",
            "Gen 99: Max F1 Score = 0.9653\n",
            "Gen 100: Max F1 Score = 0.9653\n",
            "Gen 101: Max F1 Score = 0.9653\n",
            "Gen 102: Max F1 Score = 0.9653\n",
            "Gen 103: Max F1 Score = 0.9653\n",
            "Gen 104: Max F1 Score = 0.9653\n",
            "Gen 105: Max F1 Score = 0.9653\n",
            "Gen 106: Max F1 Score = 0.9653\n",
            "Gen 107: Max F1 Score = 0.9653\n",
            "Gen 108: Max F1 Score = 0.9653\n",
            "Gen 109: Max F1 Score = 0.9653\n",
            "Gen 110: Max F1 Score = 0.9653\n",
            "Gen 111: Max F1 Score = 0.9653\n",
            "Gen 112: Max F1 Score = 0.9653\n",
            "Gen 113: Max F1 Score = 0.9653\n",
            "Gen 114: Max F1 Score = 0.9653\n",
            "Gen 115: Max F1 Score = 0.9653\n",
            "Gen 116: Max F1 Score = 0.9653\n",
            "Gen 117: Max F1 Score = 0.9653\n",
            "Gen 118: Max F1 Score = 0.9653\n",
            "Gen 119: Max F1 Score = 0.9653\n",
            "Gen 120: Max F1 Score = 0.9653\n",
            "Gen 121: Max F1 Score = 0.9653\n",
            "Gen 122: Max F1 Score = 0.9653\n",
            "Gen 123: Max F1 Score = 0.9653\n",
            "Gen 124: Max F1 Score = 0.9653\n",
            "Gen 125: Max F1 Score = 0.9653\n",
            "Gen 126: Max F1 Score = 0.9653\n",
            "Gen 127: Max F1 Score = 0.9653\n",
            "Gen 128: Max F1 Score = 0.9653\n",
            "Gen 129: Max F1 Score = 0.9653\n",
            "Gen 130: Max F1 Score = 0.9653\n",
            "Gen 131: Max F1 Score = 0.9653\n",
            "Gen 132: Max F1 Score = 0.9653\n",
            "Gen 133: Max F1 Score = 0.9653\n",
            "Gen 134: Max F1 Score = 0.9653\n",
            "Gen 135: Max F1 Score = 0.9653\n",
            "Gen 136: Max F1 Score = 0.9653\n",
            "Gen 137: Max F1 Score = 0.9653\n",
            "Gen 138: Max F1 Score = 0.9653\n",
            "Gen 139: Max F1 Score = 0.9653\n",
            "Gen 140: Max F1 Score = 0.9653\n",
            "Gen 141: Max F1 Score = 0.9653\n",
            "Gen 142: Max F1 Score = 0.9653\n",
            "Gen 143: Max F1 Score = 0.9653\n",
            "Gen 144: Max F1 Score = 0.9653\n",
            "Gen 145: Max F1 Score = 0.9653\n",
            "Gen 146: Max F1 Score = 0.9653\n",
            "Gen 147: Max F1 Score = 0.9653\n",
            "Gen 148: Max F1 Score = 0.9653\n",
            "Gen 149: Max F1 Score = 0.9653\n",
            "\n",
            "Best individual:\n",
            "logical_or(logical_or(logical_or(logical_and(logical_not(x15), logical_and(x11, logical_or(x7, logical_and(logical_not(x15), logical_or(x4, logical_and(logical_or(x8, x8), logical_not(x14))))))), logical_and(logical_and(x8, logical_or(x7, x13)), logical_or(logical_or(x13, logical_and(x5, x8)), logical_or(x4, logical_and(logical_not(x15), x12))))), logical_or(x4, logical_and(x5, x1))), logical_and(logical_or(x9, logical_or(x4, x1)), logical_or(x9, x8)))\n",
            "\n",
            "Best training F1 Score: 0.9653465346534653\n",
            "Test F1 Score: 0.9215686274509803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_individual = hof[0]\n",
        "print(\"\\nBest individual:\")\n",
        "print(best_individual)\n",
        "print(\"\\nBest training F1 Score:\", best_individual.fitness.values[0])\n",
        "test_f1 = evaluate_on_test_set(best_individual)\n",
        "print(\"Test F1 Score:\", test_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "6nHFCJsxl9sa",
        "outputId": "b7ab74ba-3eef-4114-e78f-7cd17d3143dd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hof' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c902be88fa26>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_individual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhof\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBest individual:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_individual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBest training F1 Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_individual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_on_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_individual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hof' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from deap import gp\n",
        "import graphviz\n",
        "\n",
        "# Plot the tree\n",
        "nodes, edges, labels = gp.graph(best_individual)\n",
        "\n",
        "# Create a new graph object using graphviz\n",
        "g = graphviz.Digraph(format='png')\n",
        "\n",
        "# Add nodes to the graph\n",
        "for node in nodes:\n",
        "    g.node(str(node), labels[node])\n",
        "\n",
        "# Add edges to the graph\n",
        "for edge in edges:\n",
        "    g.edge(str(edge[0]), str(edge[1]))\n",
        "\n",
        "# Render and save the graph\n",
        "g.render('best_individual_tree', view=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ubX8YVISC_ko",
        "outputId": "dd58889a-cf41-4bb2-9146-65b133dec76c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'best_individual_tree.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}