{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWwcZ3zgDAmR",
        "outputId": "ac0f0e5c-507e-4b2d-ee3c-1bce63254c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deap in /opt/anaconda3/lib/python3.12/site-packages (1.4.1)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from deap) (1.26.4)\n",
            "Requirement already satisfied: graphviz in /opt/anaconda3/lib/python3.12/site-packages (0.20.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install deap\n",
        "!pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT0FvAHXC1rf",
        "outputId": "756e6f2e-197c-410f-e53e-8cf93d04e7e9"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/lungcancer_binario.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load and preprocess the data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/lungcancer_binario.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_binary\u001b[39m(df):\n\u001b[1;32m     13\u001b[0m     df_binary \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/lungcancer_binario.csv'"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import operator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from deap import base, creator, tools, gp\n",
        "import multiprocessing\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('lungcancer_binario.csv')\n",
        "\n",
        "def convert_to_binary(df):\n",
        "    df_binary = df.copy()\n",
        "\n",
        "    for column in df_binary.columns:\n",
        "        # Verifica si la columna es binaria (0/1)\n",
        "        if df_binary[column].dtype in ['int64', 'float64']:\n",
        "            if df_binary[column].nunique() == 2:\n",
        "                df_binary[column].astype(int)  # No modificar columnas binarias\n",
        "            elif df_binary[column].nunique() > 3:\n",
        "                # Aplica binning y luego one-hot\n",
        "                df_binned = pd.cut(df_binary[column], bins=3, labels=False)\n",
        "                df_one_hot = pd.get_dummies(df_binned, prefix=column)\n",
        "                df_binary = pd.concat([df_binary, df_one_hot], axis=1).astype(int)\n",
        "                df_binary.drop(column, axis=1, inplace=True)\n",
        "            else:\n",
        "                # Aplica one-hot directamente\n",
        "                df_one_hot = pd.get_dummies(df_binary[column], prefix=column)\n",
        "                df_binary = pd.concat([df_binary, df_one_hot], axis=1).astype(int)\n",
        "                df_binary.drop(column, axis=1, inplace=True)\n",
        "        elif df_binary[column].dtype == 'object':\n",
        "            # Si la columna es categórica, aplica one-hot\n",
        "            df_one_hot = pd.get_dummies(df_binary[column], prefix=column)\n",
        "            df_binary = pd.concat([df_binary, df_one_hot], axis=1)\n",
        "            df_binary.drop(column, axis=1, inplace=True)\n",
        "\n",
        "    return df_binary\n",
        "# Convert categorical variables to binary (one-hot encoding)\n",
        "df_bin = convert_to_binary(df)\n",
        "df_bin.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxsXW-qUVAXQ",
        "outputId": "f5e6d580-a4ab-4ef1-c2c6-1a3608919bd7"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df_bin.drop(['CancerPulmon'], axis=1)\n",
        "Y = df_bin['CancerPulmon']\n",
        "\n",
        "# Convert DataFrames to NumPy arrays for faster computations\n",
        "X = X.values.astype(int)\n",
        "Y = Y.values.astype(int)\n",
        "\n",
        "# Split into train and test sets\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
        "\n",
        "# Define logical functions\n",
        "def logical_and(a, b):\n",
        "    return int(a and b)\n",
        "\n",
        "def logical_or(a, b):\n",
        "    return int(a or b)\n",
        "\n",
        "def logical_not(a):\n",
        "    return int(not a)\n",
        "\n",
        "# Number of variables (features)\n",
        "# Con esto creamos x1, x2, x3... almacenados en una lista\n",
        "num_vars = Xtrain.shape[1]\n",
        "var_names = ['x' + str(i+1) for i in range(num_vars)]\n",
        "\n",
        "# Create PrimitiveSet\n",
        "# Se crea el conjunto de primitivas \"MAIN\" (el conjunto de funciones y operadores que\n",
        "# sirven para construir inidividuos) con el tamaño del número de características\n",
        "# que tenemos en el problema\n",
        "pset = gp.PrimitiveSet(\"MAIN\", num_vars)\n",
        "# Se renombran los argumentos (por defecto llamados ARG0,ARG1...) para que se llamen (x1,x2...)\n",
        "pset.renameArguments(**{'ARG' + str(i): var_names[i] for i in range(num_vars)})\n",
        "\n",
        "# Add primitives to the set\n",
        "# Añade las funciones al conjunto de primitivas\n",
        "pset.addPrimitive(logical_and, 2)\n",
        "pset.addPrimitive(logical_or, 2)\n",
        "pset.addPrimitive(logical_not, 1)\n",
        "\n",
        "# Terminal set can include constants if needed (e.g., True/False)\n",
        "# pset.addTerminal(1)  # Optional: Add constant 'True'\n",
        "# pset.addTerminal(0)  # Optional: Add constant 'False'\n",
        "\n",
        "# Define fitness and individual classes\n",
        "# Se crea una clase FitnessMax que maximiza el fitness de los individuos\n",
        "# Se define una clase \"Individual\" que representa a los individuos de la población\n",
        "# (Se obliga a que sean árboles formados por las primitivas de antes)\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
        "\n",
        "# Create toolbox\n",
        "# Se crea una toolbox que contiene las funciones (herramientas) que se van a usar\n",
        "# para generar individuos poblaciones...\n",
        "toolbox = base.Toolbox()\n",
        "# Función para generar expresiones (gp.genHalfAndHalf sirve para crear árboles\n",
        "# utilizando crecimiento completo=hasta la máxima longitud y crecimiento\n",
        "#parcial=árboles de tamaño libre)\n",
        "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n",
        "# Función para crear individuos (usando la anterior función)\n",
        "toolbox.register(\"individual\", tools.initIterate,\n",
        "                 creator.Individual, toolbox.expr)\n",
        "# Función para crear población, llamando repetidamente a la función anterior\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Register compile function\n",
        "# Función para convertir un individuo (su árbol) en una función de Python ejecutable\n",
        "# esto sirve para poder evaluar a los individuos\n",
        "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
        "\n",
        "# Evaluation function\n",
        "# Para medir el f1-score\n",
        "def eval_individual(individual):\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    predictions = []\n",
        "    for i in range(len(Xtrain)):\n",
        "        args = tuple(Xtrain[i])\n",
        "        pred = func(*args)\n",
        "        predictions.append(pred)\n",
        "    y_pred = np.array(predictions)\n",
        "    y_true = Ytrain\n",
        "    # Compute F1 score\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / \\\n",
        "        (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f1,\n",
        "\n",
        "# Register evaluation function\n",
        "# Para añadir la función anterior al conjunto de herramientas\n",
        "toolbox.register(\"evaluate\", eval_individual)\n",
        "\n",
        "# Genetic operators\n",
        "# Funciones de selección por torneos, cruce (en un punto), generación de árboles\n",
        "#completos y mutación uniforme del árbol generado\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"mate\", gp.cxOnePoint)\n",
        "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
        "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
        "\n",
        "# Limit the height of the tree to prevent bloat\n",
        "# Estas funciones limitan, tanto el cruce como la mutación para que los árboles\n",
        "# resultantes no superen la altura definida\n",
        "# Se podrían eliminar para no limitar el crecimiento de los árboles\n",
        "MAX_HEIGHT = 5\n",
        "MAX_SIZE = 50  # Ajusta este valor según tus necesidades\n",
        "toolbox.decorate(\"mate\", gp.staticLimit(\n",
        "    key=operator.attrgetter(\"height\"), max_value=MAX_HEIGHT))\n",
        "toolbox.decorate(\"mate\", gp.staticLimit(key=len, max_value=MAX_SIZE))\n",
        "toolbox.decorate(\"mutate\", gp.staticLimit(\n",
        "    key=operator.attrgetter(\"height\"), max_value=MAX_HEIGHT))\n",
        "toolbox.decorate(\"mutate\", gp.staticLimit(key=len, max_value=MAX_SIZE))\n",
        "def main():\n",
        "    random.seed(42)\n",
        "    pop = toolbox.population(n=300)\n",
        "    hof = tools.HallOfFame(1)\n",
        "\n",
        "    # Statistics\n",
        "    # Métricas sobre el tamaño del inviduo y de su fitness\n",
        "    stats_fit = tools.Statistics(lambda ind: ind.fitness.values[0])\n",
        "    stats_size = tools.Statistics(len)\n",
        "    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
        "    mstats.register(\"avg\", np.mean)\n",
        "    mstats.register(\"std\", np.std)\n",
        "    mstats.register(\"min\", np.min)\n",
        "    mstats.register(\"max\", np.max)\n",
        "\n",
        "    # Use multiprocessing for parallel evaluations\n",
        "    # Para optimizar el proceso evolutivo\n",
        "    pool = multiprocessing.Pool()\n",
        "    toolbox.register(\"map\", pool.map)\n",
        "\n",
        "    # Evaluate the entire population\n",
        "    # Evalúa en paralelo los individuos\n",
        "    fitnesses = list(toolbox.map(toolbox.evaluate, pop))\n",
        "    for ind, fit in zip(pop, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    # Update the hall of fame with the initial population\n",
        "    hof.update(pop)\n",
        "\n",
        "    ngen = 150\n",
        "    for gen in range(ngen):\n",
        "        # Select the next generation individuals\n",
        "        offspring = toolbox.select(pop, len(pop) - 1)\n",
        "        # Clone the selected individuals\n",
        "        offspring = list(map(toolbox.clone, offspring))\n",
        "        # Apply crossover and mutation\n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "            if random.random() < 0.5:  # Curce con prob = 50%\n",
        "                toolbox.mate(child1, child2)\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "        for mutant in offspring:\n",
        "            if random.random() < 0.2: # Mutación con prob = 20%\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "        # Evaluate the individuals with invalid fitness\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "        # Replace the population with the offspring, keeping the best individual\n",
        "        pop[:] = offspring + [hof[0]]\n",
        "        # Update the hall of fame\n",
        "        hof.update(pop)\n",
        "        # Record statistics\n",
        "        record = mstats.compile(pop)\n",
        "        print(f\"Gen {gen}: Max F1 Score = {record['fitness']['max']:.4f}\")\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return pop, hof\n",
        "\n",
        "def evaluate_on_test_set(individual):\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    predictions = []\n",
        "    for i in range(len(Xtest)):\n",
        "        args = tuple(Xtest[i])\n",
        "        pred = func(*args)\n",
        "        predictions.append(pred)\n",
        "    y_pred = np.array(predictions)\n",
        "    y_true = Ytest\n",
        "    # Compute F1 score\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / \\\n",
        "        (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return f1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pop, hof = main()\n",
        "    best_individual = hof[0]\n",
        "    print(\"\\nBest individual:\")\n",
        "    print(best_individual)\n",
        "    print(\"\\nBest training F1 Score:\", best_individual.fitness.values[0])\n",
        "    test_f1 = evaluate_on_test_set(best_individual)\n",
        "    print(\"Test F1 Score:\", test_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "6nHFCJsxl9sa",
        "outputId": "b7ab74ba-3eef-4114-e78f-7cd17d3143dd"
      },
      "outputs": [],
      "source": [
        "best_individual = hof[0]\n",
        "print(\"\\nBest individual:\")\n",
        "print(best_individual)\n",
        "print(\"\\nBest training F1 Score:\", best_individual.fitness.values[0])\n",
        "test_f1 = evaluate_on_test_set(best_individual)\n",
        "print(\"Test F1 Score:\", test_f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ubX8YVISC_ko",
        "outputId": "dd58889a-cf41-4bb2-9146-65b133dec76c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from deap import gp\n",
        "import graphviz\n",
        "\n",
        "# Plot the tree\n",
        "nodes, edges, labels = gp.graph(best_individual)\n",
        "\n",
        "# Create a new graph object using graphviz\n",
        "g = graphviz.Digraph(format='png')\n",
        "\n",
        "# Add nodes to the graph\n",
        "for node in nodes:\n",
        "    g.node(str(node), labels[node])\n",
        "\n",
        "# Add edges to the graph\n",
        "for edge in edges:\n",
        "    g.edge(str(edge[0]), str(edge[1]))\n",
        "\n",
        "# Render and save the graph\n",
        "g.render('best_individual_tree', view=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
